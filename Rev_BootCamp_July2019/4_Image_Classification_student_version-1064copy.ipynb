{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Introduction to Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The great thing about the Machine Learning techniques you have been learning is that they can be applied to most forms of data. So far you have done classification on tabular data (the iris dataset) and on text data (the mbti dataset). In this test you will use the same techiques learnt there and apply it to image classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Honour Code\n",
    "I YOUR NAME, YOUR SURNAME, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the EDSA honour code (https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
    "\n",
    "Non-compliance with the honour code constitutes a material breach of contract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip # This is used in extracting the images\n",
    "\n",
    "import matplotlib.pyplot as plt # in order to plot the images to see what we are dealing with\n",
    "from sklearn.ensemble import RandomForestClassifier # you'll be using Random Forest to classify the images\n",
    "from sklearn.metrics import accuracy_score # sklearn's way of measuring accuracy\n",
    "from sklearn.metrics import classification_report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we will be using is called MNIST. This is a large dataset of handdrawn digits 0-9 and is a good dataset to learn image classification on as it requires little to no preprocessing.\n",
    "\n",
    "The dataset can be downloaded from [The MNIST Database](http://yann.lecun.com/exdb/mnist/). Download all four files. These files are the images and their respective labels and the dataset has already been split into a train and a test set.\n",
    "\n",
    "Once you've downloaded the data, make sure that the data is in the same folder as this Jupyter Notebook, and then lets begin! \n",
    "\n",
    "These files are compressed as gzip. The following two functions will extract the data for you. ** Don't change this code. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_data(filename, num_images, IMAGE_WIDTH):\n",
    "    \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\"\"\"\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(IMAGE_WIDTH * IMAGE_WIDTH * num_images)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "        data = data.reshape(num_images, IMAGE_WIDTH*IMAGE_WIDTH)\n",
    "        return data\n",
    "\n",
    "def extract_labels(filename, num_images):\n",
    "    \"\"\"Extract the labels into a vector of int64 label IDs.\"\"\"\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * num_images)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 - Extracting the data\n",
    "\n",
    "The MNIST dataset consists for 60 000 training images and 10 000 testing images. This is a lot of data! Let's not extract all of that right now. Create a function get_data that uses the above functions to extract a certain number of images and their labels from the gzip files.\n",
    "\n",
    "The function will take as input two integer values and return four variables in the form of `(X_train, y_train), (X_test, y_test)`, where `(X_train, y_train)` are the extracted images / labels of the training set, and `(X-test, y_test)` are the extracted images / labels of the testing set.\n",
    "\n",
    "Image pixel values range from 0-255. Normalise the image pixels so that they are in the range 0-1.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take two integers as input, one representing the number of training images, and the other the number of testing images.\n",
    "* Should return two `tuples` of the form `(X_train, y_train), (X_test, y_test)`.\n",
    "\n",
    "_**Note**_ that the size of the MNIST images are 28x28\n",
    "\n",
    "Usually when setting up your dataset, it is a good idea to randomly shuffle your data in case your data is ordered. Think of this as shuffle a pack of cards. Here however we aren't going to shuffle the data so that all our answers are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(num_train_images,num_test_images):\n",
    "    #your code here\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = get_data(5000,1000)\n",
    "## Print off the shape of these arrays to see what we are dealing with\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Expected Output **\n",
    "```python\n",
    "(X_train, y_train), (X_test, y_test) = get_data(5000,1000)\n",
    "## Print off the shape of these arrays to see what we are dealing with\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "(5000,)\n",
    "(1000,)\n",
    "(5000, 784)\n",
    "(1000, 784)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see what this data looks like! Right now the images are \"flattened\" into a 1-D array of length 784. In order to plot the image we first need to reshape it to the correct size of 28x28. We'll print out the respective label to make sure we are plotting the right number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_index = 2 ## Change me to view different images\n",
    "\n",
    "print(\"Label: \", y_train[image_index])\n",
    "reshaped_image = X_train[image_index].reshape((28, 28))\n",
    "\n",
    "plt.imshow(reshaped_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 - Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have formatted our data, we can fit a model using sklearn's `RandomForestClassifier` class with its default parameters and its random_state is set to 0. We'll write a function that will take as input the image and label variables that we created previously, and return a trained model.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take two numpy `arrays` as input in the form `(X_train, y_train)`.\n",
    "* Should return an sklearn `RandomForestClassifier` model which has a random state of 0.\n",
    "* The returned model should be fitted to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train):\n",
    "    #your code here\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = train_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 - Testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have trained your model, lets see how well it does on the test set. Write a function which returns the accuracy of your trained model when tested with the test set.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take the fitted model and two numpy `arrays` `X_test, y_test` as input.\n",
    "* Should return a `float` of the accuracy of the model. This number should be between zero and one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(clf, X_test, y_test):\n",
    "    #your code here\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(calculate_accuracy(clf,X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification reports gives us more information on where our model is going wrong - looking specifically at the performance caused by Type I & II errors. Write a function which returns the classification report of your test set.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take the fitted model and two numpy `arrays` `X_test, y_test` as input.\n",
    "* Should return a classification report\n",
    "\n",
    "_**Hint**_ You don't need to do this manually, sklearn has a classification report function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_class_report(clf, X_test, y_test):\n",
    "    #your code here\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(get_class_report(clf,X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Plotting the results\n",
    "\n",
    "Lets actually see if your model has trained correctly. Lets plot some of the images with their predicted labels. Since we don't have the predictions stored in our notebooks memory, we need to call the predict function here first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test)\n",
    "\n",
    "image_index = 1 ## Change me to see other predictions\n",
    "\n",
    "print(\"Predicted Label: \",preds[image_index])\n",
    "plt.imshow(X_test[image_index].reshape((28, 28)), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice work! Since we didn't use all the data in the beginning, there is a chance our performance can improve. Go change the amount of data we use to see how it affects the accuracy of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
